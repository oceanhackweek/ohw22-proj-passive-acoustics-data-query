{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3982fcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onc in c:\\users\\maria\\anaconda3\\lib\\site-packages (2.3.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\maria\\anaconda3\\lib\\site-packages (from onc) (1.20.3)\n",
      "Requirement already satisfied: requests in c:\\users\\maria\\anaconda3\\lib\\site-packages (from onc) (2.26.0)\n",
      "Requirement already satisfied: humanize in c:\\users\\maria\\anaconda3\\lib\\site-packages (from onc) (4.3.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from onc) (1.26.7)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\maria\\anaconda3\\lib\\site-packages (from onc) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from python-dateutil->onc) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from requests->onc) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from requests->onc) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from requests->onc) (2021.10.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#installs\n",
    "%pip install onc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "87df2b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import onc\n",
    "from onc.onc import ONC\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "from shapely.geometry import Polygon\n",
    "from copy import copy\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "#token\n",
    "onc = ONC(\"57ffdc86-22ab-433f-b613-7d755fa7635c\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "52aec406",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to read all the user inputs (location and date)\n",
    "\n",
    "def onc_data(*args,**kwargs):\n",
    "    \n",
    "    filter_dict_short = {\"deviceCategoryCode\": \"HYDROPHONE\",\n",
    "    \"dataProductCode\": \"AD\",\n",
    "    \"returnOptions\": \"all\",}\n",
    "    filter_dict_long = {\"deviceCategoryCode\": \"HYDROPHONE\",}\n",
    "\n",
    "    temp_short = copy(filter_dict_short)\n",
    "    temp_long = copy(filter_dict_long)\n",
    "    #print(kwargs)\n",
    "    MinTime = kwargs.get(\"min_time\", None)\n",
    "\n",
    "    if not MinTime:\n",
    "        MinTime = datetime(2000, 1, 1)\n",
    "    temp_short[\"dateFrom\"] = MinTime.strftime(\"%Y-%m-%d\")\n",
    "    temp_long[\"dateFrom\"] = MinTime.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "    MaxTime = kwargs.get(\"max_time\", None)\n",
    "    if not MaxTime:\n",
    "        MaxTime = datetime.now() + timedelta(days = 2)\n",
    "    temp_short[\"dateTo\"] = MaxTime.strftime(\"%Y-%m-%d\")\n",
    "    temp_long[\"dateTo\"] = MaxTime.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    \n",
    "    # check\n",
    "    if MaxTime - MinTime > timedelta(days = 60):\n",
    "        # response will take too long, do other query and alert user\n",
    "        # call function that checks if data exists and returns generic urls\n",
    "        #print(temp_long)\n",
    "        df = onc_long_date_range(temp_long,min_long, max_long, min_lat, max_lat)\n",
    "        \n",
    "    else:\n",
    "        #call function that returns specific urls\n",
    "        #print(temp_short)\n",
    "        df = onc_short_date_range(temp_short, temp_long, min_long, max_long, min_lat, max_lat)\n",
    "        \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6dcfca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get bounding boxes of locations with hydrophone data\n",
    "def hydrophone_locations(temp_long):\n",
    "    locations = onc.getLocations(temp_long)\n",
    "    df = gpd.GeoDataFrame(locations)\n",
    "    df_separate = gpd.GeoDataFrame([\n",
    "    {\n",
    "        **location, \n",
    "        'geometry': box(\n",
    "            location['bbox']['minLon'], \n",
    "            location['bbox']['minLat'], \n",
    "            location['bbox']['maxLon'], \n",
    "            location['bbox']['maxLat']\n",
    "        )\n",
    "    } for location in locations\n",
    "])\n",
    "    return(df_separate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a965a028",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#function to input locations (from user) and get output of subset of \n",
    "#locations (that intersects with user input bounding box) with hydrophone data\n",
    "def subset_locations(temp_long, min_long, max_long, min_lat, max_lat):\n",
    "    gdf = hydrophone_locations(temp_long)\n",
    "    subset = gdf.cx[min_long:max_long, min_lat:max_lat]\n",
    "    locations_codes = subset.locationCode\n",
    "    return(subset, locations_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "0e14f0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def onc_long_date_range(temp_long, min_long, max_long, min_lat, max_lat):\n",
    "    print(\"Date range is too long for specific data url query from Ocean Networks Canada. However, the requested data exists at https://data.oceannetworks.ca/DataSearch\")\n",
    "    subset, locations_codes = subset_locations(temp_long, min_long, max_long, min_lat, max_lat)\n",
    "    df = pd.DataFrame(subset)\n",
    "    df_bbox = pd.DataFrame.from_records(subset['bbox'],index = df.index)\n",
    "    newdf = pd.DataFrame()\n",
    "    newdf['filename']=\"\"\n",
    "    newdf['min_time']=np.nan\n",
    "    newdf['max_time']=np.nan\n",
    "    newdf['min_lat']=df_bbox['minLat']\n",
    "    newdf['max_lat']=df_bbox['maxLat']\n",
    "    newdf['min_long']=df_bbox['minLon']\n",
    "    newdf['max_long']=df_bbox['maxLon']\n",
    "    newdf['min_freq']=np.nan\n",
    "    newdf['max_freq']=np.nan\n",
    "    newdf['min_depth']=df_bbox['minDepth']\n",
    "    newdf['max_depth']=df_bbox['maxDepth']\n",
    "    newdf['data_url'] = df['dataSearchURL']\n",
    "    \n",
    "    return(newdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "f6e81350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onc_short_date_range(temp_short, temp_long, min_long, max_long, min_lat, max_lat):\n",
    "    print(\"Extracting data urls from Ocean Networks Canada\")\n",
    "    subset, location_code_list = subset_locations(temp_long, min_long, max_long, min_lat, max_lat)\n",
    "    query_list = []\n",
    "    url_list = []\n",
    "    for location_code in location_code_list:\n",
    "        temp2 = copy(temp_short)\n",
    "        temp2['locationCode'] = location_code\n",
    "        query_list.append(temp2)\n",
    "    for query in query_list:\n",
    "        results = onc.archive.getListByLocation(query,allPages=True)\n",
    "        if not results['files']:\n",
    "            pass\n",
    "        else:\n",
    "            urls = [\n",
    "        {\n",
    "            **file,\n",
    "            \"fullPath\": f\"{onc.archive._serviceUrl('archivefiles')}?token={onc.archive._config('token')}&method=getFile&filename={file['filename']}\",\n",
    "        }\n",
    "        for file in results['files']\n",
    "    ]\n",
    "            url_list.append(urls)\n",
    "\n",
    "    \n",
    "    for i in range(len(url_list)):\n",
    "        df = pd.DataFrame(url_list[i])\n",
    "        newdf = pd.DataFrame()\n",
    "\n",
    "        newdf['filename'] = df['filename']\n",
    "        newdf['min_time'] = df['dateFrom']\n",
    "        newdf['max_time'] = df['dateTo']\n",
    "        newdf['min_lat']=np.nan\n",
    "        newdf['max_lat']=np.nan\n",
    "        newdf['min_long']=np.nan\n",
    "        newdf['max_long']=np.nan\n",
    "        newdf['min_freq']=np.nan\n",
    "        newdf['max_freq']=np.nan\n",
    "        newdf['min_depth']=np.nan\n",
    "        newdf['max_depth']=np.nan\n",
    "        newdf['data_url'] = df['fullPath']\n",
    "        if i != 0:\n",
    "            newdf = pd.concat([olddf, newdf], axis=0, ignore_index=True)\n",
    "        olddf = newdf\n",
    "    \n",
    "    return(newdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "8da43fb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range is too long for specific data url query from Ocean Networks Canada. However, the requested data exists at https://data.oceannetworks.ca/DataSearch\n",
      "   filename  min_time  max_time    min_lat    max_lat    min_long    max_long  \\\n",
      "0       NaN       NaN       NaN  48.345773  48.345773 -126.157685 -126.157685   \n",
      "2       NaN       NaN       NaN  48.699407  48.699407 -126.872425 -126.872425   \n",
      "3       NaN       NaN       NaN  48.699407  48.699407 -126.872425 -126.872425   \n",
      "4       NaN       NaN       NaN  50.020767  50.020767 -125.235350 -125.235350   \n",
      "5       NaN       NaN       NaN  54.258806  54.258806 -130.430694 -130.430694   \n",
      "6       NaN       NaN       NaN  49.043300  49.043300 -123.316108 -123.316108   \n",
      "7       NaN       NaN       NaN  49.043300  49.043300 -123.316108 -123.316108   \n",
      "8       NaN       NaN       NaN  49.043300  49.043300 -123.316108 -123.316108   \n",
      "9       NaN       NaN       NaN  49.043300  49.043300 -123.316108 -123.316108   \n",
      "10      NaN       NaN       NaN  48.780567  48.780567 -123.051433 -123.051433   \n",
      "11      NaN       NaN       NaN  48.813851  48.813851 -125.274604 -125.274604   \n",
      "12      NaN       NaN       NaN  49.153637  49.154343 -124.803062 -124.802041   \n",
      "13      NaN       NaN       NaN  47.949300  47.949300 -129.098351 -129.098351   \n",
      "14      NaN       NaN       NaN  53.974785  53.974785 -128.657183 -128.657183   \n",
      "15      NaN       NaN       NaN  48.766617  48.766617 -123.091017 -123.091017   \n",
      "16      NaN       NaN       NaN  47.763135  47.763135 -127.758548 -127.758548   \n",
      "17      NaN       NaN       NaN  47.763135  47.763135 -127.758548 -127.758548   \n",
      "18      NaN       NaN       NaN  48.651332  48.651641 -123.486170 -123.485684   \n",
      "19      NaN       NaN       NaN  49.039432  49.039524 -123.425438 -123.425120   \n",
      "20      NaN       NaN       NaN  49.043226  49.043226 -123.316137 -123.316137   \n",
      "21      NaN       NaN       NaN  49.085321  49.085321 -123.329648 -123.329648   \n",
      "\n",
      "    min_freq  max_freq  min_depth  max_depth  \\\n",
      "0        NaN       NaN      643.0      643.0   \n",
      "2        NaN       NaN     1315.0     1315.0   \n",
      "3        NaN       NaN     1315.0     1315.0   \n",
      "4        NaN       NaN        8.4        8.4   \n",
      "5        NaN       NaN       28.0       28.0   \n",
      "6        NaN       NaN      164.0      164.0   \n",
      "7        NaN       NaN      164.0      164.0   \n",
      "8        NaN       NaN      164.0      164.0   \n",
      "9        NaN       NaN      164.0      164.0   \n",
      "10       NaN       NaN       15.0       15.0   \n",
      "11       NaN       NaN       95.0       95.0   \n",
      "12       NaN       NaN      107.0      109.0   \n",
      "13       NaN       NaN     2189.0     2189.0   \n",
      "14       NaN       NaN       44.1       44.1   \n",
      "15       NaN       NaN       20.0       20.0   \n",
      "16       NaN       NaN     2670.0     2670.0   \n",
      "17       NaN       NaN     2670.0     2670.0   \n",
      "18       NaN       NaN       94.0       98.0   \n",
      "19       NaN       NaN      297.0      298.0   \n",
      "20       NaN       NaN      163.0      163.0   \n",
      "21       NaN       NaN      105.0      105.0   \n",
      "\n",
      "                                                     data_url  \n",
      "0      http://data.oceannetworks.ca/DataSearch?location=BACND  \n",
      "2   http://data.oceannetworks.ca/DataSearch?location=CQS64.H1  \n",
      "3   http://data.oceannetworks.ca/DataSearch?location=CQS64.H2  \n",
      "4       http://data.oceannetworks.ca/DataSearch?location=CRIP  \n",
      "5       http://data.oceannetworks.ca/DataSearch?location=DIIP  \n",
      "6   http://data.oceannetworks.ca/DataSearch?location=ECHO3.H1  \n",
      "7   http://data.oceannetworks.ca/DataSearch?location=ECHO3.H2  \n",
      "8   http://data.oceannetworks.ca/DataSearch?location=ECHO3.H3  \n",
      "9   http://data.oceannetworks.ca/DataSearch?location=ECHO3.H4  \n",
      "10      http://data.oceannetworks.ca/DataSearch?location=EPSI  \n",
      "11      http://data.oceannetworks.ca/DataSearch?location=FGPD  \n",
      "12     http://data.oceannetworks.ca/DataSearch?location=JAKOC  \n",
      "13      http://data.oceannetworks.ca/DataSearch?location=KEMF  \n",
      "14      http://data.oceannetworks.ca/DataSearch?location=KVIP  \n",
      "15      http://data.oceannetworks.ca/DataSearch?location=MHSI  \n",
      "16   http://data.oceannetworks.ca/DataSearch?location=NC27.H3  \n",
      "17   http://data.oceannetworks.ca/DataSearch?location=NC27.H4  \n",
      "18      http://data.oceannetworks.ca/DataSearch?location=PVIP  \n",
      "19     http://data.oceannetworks.ca/DataSearch?location=SCVIP  \n",
      "20     http://data.oceannetworks.ca/DataSearch?location=SEVIP  \n",
      "21     http://data.oceannetworks.ca/DataSearch?location=USSLP  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#standardized_column_output = [\"filename\", \"min_time\", \"max_time\", \"min_lat\", \n",
    "#\"max_lat\", \"min_long\", \"max_long\", \"min_freq\", \"max_freq\", \"min_depth\", \"max_depth\", \"data_url\"]\n",
    "#test\n",
    "input_dict = {\"min_long\": -150,\n",
    "              \"max_long\": -100,\n",
    "              \"min_lat\": 30,\n",
    "              \"max_lat\": 60,\n",
    "              \"min_time\": datetime(2020, 1, 1),\n",
    "              \"max_time\": datetime(2020, 4, 2)\n",
    "             }\n",
    "df = onc_data(filter_dict_long, filter_dict_short, **input_dict)\n",
    "pd.options.display.max_colwidth = 200\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
